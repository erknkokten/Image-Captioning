{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We provided 3 .py and 3 .ipynb file. If you want to run the code, you can run it in Google Colab.\n",
        "To do so, the Google Drive link which includes the dataset paths alongside with model check points is given below.\n",
        "https://drive.google.com/drive/folders/1rsKAKgeTv3WeX5A_hko5w8j2H4RdNcfU?usp=sharing\n",
        "\n",
        "IMPORTANT NOTE: YOU CANNOT RUN THIS CODE IN YOUR COMPUTER, OR EVEN IN YOUR OWN COLAB ENVIRONMENT. YOU NEED TO HAVE .pkl AND .h5 FILES TO PROCEED. FOR THE FINAL PROJECT OF EE443 COURSE, EVERYTHING YOU NEED IS AVAILABLE IN THE DRIVE LINK PROVIDED ABOVE. CONNECT IT IN YOUR COLAB ENVIRONMENT, AND YOU ARE READY TO GO.\n",
        "\n",
        "This code is now set to be using the latest checkpoint, only for **TESTING PURPOSES**. In this way, the code will not train anything. If you want to see training results, turn the flag below **False**.\n",
        "\n",
        "\n",
        "1-Links to other Google Colab environments\n",
        "\n",
        "1.   GRU + Attention Model: https://colab.research.google.com/drive/1Q4ueHEDtLcCVnZBcPsjfo1VWOcGua2cN?usp=sharing\n",
        "2.   GRU + Attention Model with GloVE word embedding: https://colab.research.google.com/drive/1VmJmFsE5JW0Hno3oLbKnfH5fDqnsuMjW?usp=sharing\n",
        "3.   LSTM Model: https://colab.research.google.com/drive/1_haPqb1kS1oVQfQSURitltkC5faJTmnn?usp=sharing\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dqps9ejiurGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########IF YOU WANT TO TRAIN, SET THE FOLLOWING FLAG FALSE##############\n",
        "flag = True\n"
      ],
      "metadata": {
        "id": "09g8hGjO14ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXHSx8yBquVf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J0p-WSPwoTE"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/drive/MyDrive/Dataset/test_data.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q test_data.zip\n",
        "!rm test_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Dataset/train_data.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q train_data.zip\n",
        "!rm train_data.zip"
      ],
      "metadata": {
        "id": "E0P3y1WjWsS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiMDMval7nX0"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "import collections\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import InceptionV3, InceptionResNetV2, EfficientNetB7, efficientnet\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import tensorflow.keras.utils\n",
        "import h5py\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbOZSwY7WbgH"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBMBBIO43NTT"
      },
      "outputs": [],
      "source": [
        "test_img_path = np.array(listdir(\"/content/content/drive/MyDrive/Dataset/test\"))\n",
        "#train_img_path =np.array(listdir(\"train\"))\n",
        "#for deleting the non-existent images\n",
        "a = None\n",
        "for i in test_img_path:\n",
        "    try:\n",
        "        a = imread(\"/content/content/drive/MyDrive/Dataset/test/\"+ i )\n",
        "    except:\n",
        "        os.remove(\"/content/content/drive/MyDrive/Dataset/test/\"+ i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = np.array(listdir(\"/content/content/drive/MyDrive/Dataset/train\"))\n",
        "#train_img_path =np.array(listdir(\"train\"))\n",
        "\n",
        "#for deleting the non-existent images\n",
        "a = None\n",
        "for i in train_img_path:\n",
        "    try:\n",
        "        a = imread(\"/content/content/drive/MyDrive/Dataset/train/\"+ i )\n",
        "    except:\n",
        "        os.remove(\"/content/content/drive/MyDrive/Dataset/train/\"+ i)\n",
        "os.remove(\"/content/content/drive/MyDrive/Dataset/train/59999 (1).jpg\")\n",
        "os.remove(\"/content/content/drive/MyDrive/Dataset/train/82782 (1).jpg\")\n"
      ],
      "metadata": {
        "id": "T1CSFAT9Yptw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swv5XuysI8Qn"
      },
      "outputs": [],
      "source": [
        "def load_image_inception(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    img_index = int(image_path.numpy().decode().split('/')[-1].split('.')[0])\n",
        "    return img, img_index\n",
        "\n",
        "def load_image_inceptionEval(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    img_index = int(image_path.split('/')[-1].split('.')[0])\n",
        "    return img, img_index\n",
        "\n",
        "def load_image_efNet(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (600, 600))\n",
        "    img = tf.image.convert_image_dtype(img,dtype=tf.float32)\n",
        "    img = efficientnet.preprocess_input(img)\n",
        "    img_index = int(image_path.numpy().decode().split('\\\\')[1].split('.')[0])\n",
        "    return img, img_index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he3Yjo7TI8cS"
      },
      "outputs": [],
      "source": [
        "train = h5py.File('/content/drive/MyDrive/Dataset/eee443_project_dataset_train.h5', 'r')\n",
        "test = h5py.File('/content/drive/MyDrive/Dataset/eee443_project_dataset_test.h5', 'r')\n",
        "#Captions for training images\n",
        "train_cap = train['train_cap']\n",
        "train_cap = np.array(train_cap)\n",
        "#The indices of training images\n",
        "train_imid = train['train_imid']\n",
        "train_imid = np.array(train_imid) -1\n",
        "#Pretrained feature vector for training images !!!USING IT WILL HALVE THE GRADE!!!!\n",
        "train_ims = train['train_ims']\n",
        "train_ims = np.array(train_ims)\n",
        "#Flickr URLs for training images\n",
        "train_url = train['train_url']\n",
        "train_url = np.array(train_url)\n",
        "#dictionary for converting words to vocabulary indices\n",
        "word_code = train['word_code']\n",
        "word_code = np.array(word_code)\n",
        "#Captions for testing images\n",
        "test_caps = test['test_caps']\n",
        "test_caps = np.array(test_caps)\n",
        "#The indices of testing images\n",
        "test_imid = test['test_imid']\n",
        "test_imid = np.array(test_imid) \n",
        "#Pretrained feature vector for testing images !!!USING IT WILL HALVE THE GRADE!!!!\n",
        "test_ims = test['test_ims']\n",
        "test_ims = np.array(test_ims)\n",
        "#Flickr URLs for testing images\n",
        "test_url = test['test_url']\n",
        "test_url = np.array(test_url)\n",
        "\n",
        "\n",
        "word_code[0].tolist()\n",
        "word_indices = word_code[0].tolist()\n",
        "word_indices = np.array(word_indices, dtype='int')\n",
        "\n",
        "words = np.array(word_code.dtype.descr)[:,0]\n",
        "\n",
        "\n",
        "test_img_path = np.array(listdir(\"/content/content/drive/MyDrive/Dataset/test\"))\n",
        "train_img_path =np.array(listdir(\"/content/content/drive/MyDrive/Dataset/train\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting pretrained InceptionV3 model \n",
        "inception = InceptionV3(weights='imagenet')\n",
        "inceptionv3_model = Model(inception.input, inception.layers[-3].output)"
      ],
      "metadata": {
        "id": "DTprZNQuOy2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to map index to real world\n",
        "def getCaps(id):\n",
        "    captionMatrix = []\n",
        "    for i in np.where(train_imid == id)[0]:\n",
        "        captionMatrix.append(train_cap[i, :])\n",
        "    return np.array(captionMatrix)\n",
        "\n",
        "#Function to map index to real world for test data\n",
        "def getCapsTest(id):\n",
        "    captionMatrix = []\n",
        "    for i in np.where(test_imid == id)[0]:\n",
        "        captionMatrix.append(test_caps[i, :])\n",
        "    return np.array(captionMatrix)\n",
        "\n",
        "#Function to map index to string array\n",
        "def readCaps(captionMatrix):\n",
        "    str = \"\"\n",
        "    str_arr = []\n",
        "    for k in captionMatrix:\n",
        "        str = \"\"\n",
        "        for i in k:\n",
        "          indices = np.where(word_indices == i)[0][0]\n",
        "          word = words[indices]\n",
        "          if i == k[-1]:\n",
        "              str = str + word\n",
        "          else:\n",
        "              str = str + word + \" \"\n",
        "        str_arr.append(str)\n",
        "    return str_arr\n",
        "#Image loader for generating pickle file for train dataset\n",
        "#Pickle file increases the process speed of data in training\n",
        "def imloader(dataset):\n",
        "    batch_size=500\n",
        "    feature_lst = None\n",
        "    index_lst = None\n",
        "    captions = None\n",
        "    with open(\"train_data.pkl\", \"wb\") as outfile:\n",
        "      for data in tqdm(dataset.batch(batch_size)):\n",
        "          image = data[0]\n",
        "          index = data[1].numpy()\n",
        "          feature = inceptionv3_model(image).numpy()\n",
        "\n",
        "          for i in range(feature.shape[0]):\n",
        "              feature_lst = (feature[i].squeeze().reshape((64,2048)))\n",
        "              index_lst = (index[i])\n",
        "              captions = (np.array(getCaps(index[i])))\n",
        "              pickle.dump((feature_lst, index_lst, captions), outfile)\n",
        "      outfile.close()\n",
        "      return None\n",
        "#Image loader for generating pickle file for validation dataset\n",
        "#Pickle file increases the process speed of data in validation     \n",
        "def imloader_val(dataset):\n",
        "    batch_size=500\n",
        "    feature_lst = None\n",
        "    index_lst = None\n",
        "    captions = None\n",
        "    with open(\"test_data.pkl\", \"wb\") as outfile:\n",
        "      for data in tqdm(dataset.batch(batch_size)):\n",
        "\n",
        "          image = data[0]\n",
        "          index = data[1].numpy()\n",
        "          feature = inceptionv3_model(image).numpy()\n",
        "          for i in range(feature.shape[0]):\n",
        "              feature_lst = (feature[i].squeeze().reshape((64,2048)))\n",
        "              index_lst = (index[i])\n",
        "              captions = (np.array(getCaps(index[i])))\n",
        "              pickle.dump((feature_lst, index_lst, captions), outfile)\n",
        "\n",
        "      outfile.close()\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "JQ1WhZ0xzzix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az9EBuEUPW1z"
      },
      "outputs": [],
      "source": [
        "#Data loading and train validation split 80%-20%\n",
        "trainDataset = tf.data.Dataset.list_files(\"/content/content/drive/MyDrive/Dataset/train/*.jpg\", shuffle=True).map(lambda x: tf.py_function(load_image_inception, [x], [tf.float32, tf.int32]))\n",
        "trainData = trainDataset.take(int(len(train_img_path)*0.80))\n",
        "validationData = trainDataset.skip(int(len(train_img_path)*0.80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkGSQnw-ScwJ"
      },
      "outputs": [],
      "source": [
        "if(not flag):\n",
        "  #Batchwise pickle generation\n",
        "  imloader(trainData)\n",
        "  imloader_val(validationData)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data yield operation definition for Dataset object of Tensorflow\n",
        "def data_loader(filename):\n",
        "   with open(filename, \"rb\") as f:\n",
        "        while 1:\n",
        "            try:\n",
        "\n",
        "                yield pickle.load(f)\n",
        "            except EOFError:\n",
        "                break\n",
        "\n",
        "trainDataset_inception = tf.data.Dataset.from_generator(data_loader, args=['/content/drive/MyDrive/Dataset/train_data.pkl'], output_types=(tf.float32,tf.int32, tf.int32))\n",
        "valDataset_inception = tf.data.Dataset.from_generator(data_loader, args=['/content/drive/MyDrive/Dataset/test_data.pkl'], output_types=(tf.float32,tf.int32, tf.int32))"
      ],
      "metadata": {
        "id": "1o0p60Z2XCbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBH_Xo4cnu0e"
      },
      "outputs": [],
      "source": [
        "#initilize settings for training\n",
        "BATCH_SIZE = 1000\n",
        "BUFFER_SIZE = 1000\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "num_steps = 20000 // BATCH_SIZE\n",
        "\n",
        "features_shape = 2048\n",
        "\n",
        "#implementation of encoder mechanism\n",
        "#inspired from https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "class Encoder(tf.keras.Model):\n",
        "    #decreasing output of inceptionv3 model to make it fit into embedding matrix\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        #two fully connected layer is enough for understanding relation\n",
        "        self.fc2 = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.fc1 = tf.keras.layers.Dense(2*embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "      #ReLU activation function is used\n",
        "        x = self.fc1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x\n",
        "#implementation of decoder mechanism\n",
        "#inspired from https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.units = units\n",
        "    #create embedding layer as matrix of shape vocabulary size 1004 x 256\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    #initializing lstm layers for future use\n",
        "    self.lstm1 = tf.keras.layers.LSTM(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.lstm2 = tf.keras.layers.LSTM(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    #sequention 2 fully connected layers to better understand word, feature interaction\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "  def call(self, x, features, hidden):\n",
        "   \n",
        "    x = self.embedding(x)\n",
        "    features = tf.reduce_sum(features, axis=0, keepdims=True)\n",
        "    #pass sentence input through word embedding \n",
        "    x = tf.concat([tf.expand_dims(features,1), x], axis=-1)\n",
        "    #give input of concated features to LSTM layer \n",
        "    output = self.lstm1(x)\n",
        "\n",
        "    #Pass data through fully connected layers and set shape according to desired output (1x17)\n",
        "    x = self.fc1(output[0])\n",
        "\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "\n",
        "\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x, None\n",
        "\n",
        "\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))\n",
        "\n",
        "\n",
        "#Create adam optimizer which performs well on similar tasks\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate= 0.001)\n",
        "#Use Sparse Categorical Crossentropy as loss function\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "encoder = Encoder(embedding_dim)\n",
        "decoder = Decoder(embedding_dim, units, 1004)\n",
        "\n",
        "#loss function calculation \n",
        "def loss_function(real, pred):\n",
        "  loss_call = loss_object(real, pred)\n",
        "  loss_result = loss_call * tf.cast(tf.math.logical_not(tf.math.equal(real, 0)), dtype=loss_call.dtype)\n",
        "  average_loss = tf.reduce_mean(loss_result)\n",
        "  return average_loss\n",
        "\n",
        "checkpoint_path = \"./checkpoints/lstm\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer=optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=50)\n",
        "\n",
        "\n",
        "start_epoch = 0\n",
        "#restore the latest checkpoint if there is any\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  path_to_latest_checkpoint = ckpt_manager.latest_checkpoint\n",
        "  last_index_of_checkpoint = path_to_latest_checkpoint.split('-')\n",
        "  start_epoch = int(last_index_of_checkpoint[-1])\n",
        "  # checkpoint restore\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "\n",
        "\n",
        "if(flag):\n",
        "  ckpt.restore(\"/content/drive/MyDrive/Dataset/checkpoints/lstm/ckpt-20\")\n",
        "  start_epoch = 20\n",
        "\n",
        "\n",
        "loss_plot = []\n",
        "@tf.function\n",
        "def train_step(img_tensor, ground_truth):\n",
        "  loss = 0\n",
        "  caption_count = ground_truth.shape[0]\n",
        "  caption_length = ground_truth.shape[1]\n",
        "  temp_caption = decoder.reset_state(batch_size=caption_count)\n",
        "\n",
        "  dec_input = tf.expand_dims([1] * caption_count, 1)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      #pass inceptionv3 outputs through encoder\n",
        "      features = encoder(img_tensor)\n",
        "      for i in range(1, caption_length):\n",
        "          # passing the features through the decoder\n",
        "          predictions, temp_caption = decoder(dec_input, features, temp_caption)\n",
        "          loss += loss_function(ground_truth[:, i], predictions)\n",
        "          #populate words to add into decoder input as next step\n",
        "          dec_input = tf.expand_dims(ground_truth[:, i], 1)\n",
        "\n",
        "  \n",
        "  #declare conponents for backpropagation to calculate gradients\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, (loss / int(caption_length))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_plot=[]\n",
        "num_of_total_epochs = 20\n",
        "#########################################\n",
        "\n",
        "for epoch in range(start_epoch, num_of_total_epochs):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    avg_batch_loss_total = 0\n",
        "    counter = 0\n",
        "    for (batch, (img_tensor, index, ground_truth)) in enumerate(trainDataset_inception.take(20000)):\n",
        "        ground_truth = tf.reshape(ground_truth[0],(1,17))\n",
        "        batch_loss, t_loss = train_step(img_tensor, ground_truth)\n",
        "        total_loss = total_loss + t_loss\n",
        "        counter += 1\n",
        "        if batch % 1000 == 0:\n",
        "            average_batch_loss = batch_loss.numpy()/int(ground_truth.shape[1])\n",
        "            print('Epoch {} Batch {} Loss {}'.format(epoch+1,batch,average_batch_loss))\n",
        "\n",
        "\n",
        "\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot.append(total_loss / counter)\n",
        "    #save each epoch \n",
        "    ckpt_manager.save()\n",
        "\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss/counter:.6f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')\n",
        "##########################################\n",
        "\n"
      ],
      "metadata": {
        "id": "FlqV2CtI_kzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_plot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "70RUpXZ4hngL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def validation(img_tensor, target):\n",
        "    loss = 0\n",
        "    caption_count = ground_truth.shape[0]\n",
        "    caption_length = ground_truth.shape[1]\n",
        "    temp_caption = decoder.reset_state(batch_size=caption_count)\n",
        "    dec_input = tf.expand_dims([1] * caption_count, 1)\n",
        "    with tf.GradientTape() as tape:\n",
        "        #pass inceptionv3 outputs through encoder\n",
        "        features = encoder(img_tensor)\n",
        "        for i in range(1, caption_length):\n",
        "            #get output of decoder \n",
        "            predictions, temp_caption = decoder(dec_input, features, temp_caption)\n",
        "            loss += loss_function(ground_truth[:, i], predictions)\n",
        "            #populate words to add into decoder input as next step\n",
        "            dec_input = tf.expand_dims(ground_truth[:, i], 1)\n",
        "    return loss, (loss / int(caption_length))"
      ],
      "metadata": {
        "id": "bXzzzAbXPjsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(not flag):\n",
        "  num_of_total_epochs = 21\n",
        "  validation_loss = []\n",
        "  for epoch in range(1, num_of_total_epochs):\n",
        "      \n",
        "      path = ckpt_manager.latest_checkpoint\n",
        "      index = path.find(\"ckpt-\")\n",
        "      path = path[:index+5] + str(epoch)\n",
        "      ckpt.restore(path)\n",
        "      start = time.time()\n",
        "      total_loss = 0\n",
        "      avg_batch_loss_total = 0\n",
        "      counter = 0\n",
        "      for (batch, (img_tensor, index, targets)) in enumerate(valDataset_inception):\n",
        "          batch_loss, t_loss = validation(img_tensor, tf.reshape(targets[0],(1,17)))\n",
        "          total_loss += t_loss\n",
        "          counter += 1\n",
        "          if batch % 3000 == 0:\n",
        "              average_batch_loss = batch_loss.numpy()/int(targets.shape[1])\n",
        "              avg_batch_loss_total += average_batch_loss\n",
        "              print('Epoch {} Batch {} Loss {}'.format(epoch,batch,average_batch_loss))\n",
        "      print(total_loss / counter)\n",
        "      validation_loss.append(total_loss / counter)\n"
      ],
      "metadata": {
        "id": "ZTw1WRchPkma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(not flag):\n",
        "  temp_loss = []\n",
        "  for y, loss in enumerate(validation_loss):\n",
        "    temp_loss.append(loss)\n",
        "  plt.plot(loss_plot, label = 'Train Loss')\n",
        "  plt.plot(temp_loss, label = 'Validation Loss')\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Sparse Categorical Crossentropy\")\n",
        "  plt.title(\"Sparse Categorical Crossentropy vs Epoch for Validation and Train Data\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "sU-0tMj6eV3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valgen = data_loader(\"/content/drive/MyDrive/Dataset/test_data.pkl\")"
      ],
      "metadata": {
        "id": "ao4FcWcCbY1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzqw6zx7TQki"
      },
      "outputs": [],
      "source": [
        "def evaluate(image):\n",
        "    #prepare input\n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "    inception_out = inceptionv3_model(tf.expand_dims(load_image_inceptionEval(image)[0],0))\n",
        "    inception_out = tf.reshape(inception_out, (-1, inception_out.shape[3]))\n",
        "    #pass through encoder\n",
        "    features = encoder(inception_out)\n",
        "    temp_input = tf.expand_dims(tf.expand_dims(1, 0), axis=0)\n",
        "    result = []\n",
        "    #make prediction for all words iteratively\n",
        "    for i in range(17):\n",
        "        predictions, hidden = decoder(temp_input, features, hidden)\n",
        "        pred_categoric_out = tf.random.categorical(predictions, 1)\n",
        "        pred_categoric_out = pred_categoric_out[0][0]\n",
        "        ids = pred_categoric_out.numpy()\n",
        "        dec_output_word = tf.compat.as_text(words[np.where(word_indices == ids)][0])\n",
        "        result.append(dec_output_word)\n",
        "        if dec_output_word == 'x_END_':\n",
        "            return result\n",
        "        temp_input = tf.expand_dims([ids], 0)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call eval function with given data\n",
        "iterated = next(valgen)\n",
        "image = \"/content/content/drive/MyDrive/Dataset/train/\"+ str(iterated[1])+\".jpg\"\n",
        "result = evaluate(image)\n",
        "res = imread(image)\n",
        "capt_real = readCaps(getCaps(iterated[1]))\n",
        "temp_cap = capt_real[0]\n",
        "temp_cap = temp_cap[9:temp_cap.find(' x_END_')]\n",
        "plt.title('Real Caption:'+temp_cap + '\\n'+'Prediction Caption:' + ' '.join(result[:-1]))\n",
        "plt.imshow(res)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ue2GRFvb-sIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WuMu9E1RLb"
      },
      "outputs": [],
      "source": [
        "def evaluate_test(image):\n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "    #pass through encoder\n",
        "    features = encoder(image)\n",
        "    temp_input = tf.expand_dims(tf.expand_dims(1, 0), axis=0)\n",
        "    result = []\n",
        "    #make prediction for all words iteratively\n",
        "    for i in range(17):\n",
        "        predictions, hidden = decoder(temp_input,features,hidden)\n",
        "        pred_categoric_out = tf.random.categorical(predictions, 1)\n",
        "        pred_categoric_out = pred_categoric_out[0][0]\n",
        "        ids = pred_categoric_out.numpy()\n",
        "        dec_output_word = tf.compat.as_text(words[np.where(word_indices == ids)][0])\n",
        "        result.append(dec_output_word)\n",
        "        if dec_output_word == 'x_END_':\n",
        "            return result\n",
        "        temp_input = tf.expand_dims([ids], 0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYVKpGE32eul"
      },
      "outputs": [],
      "source": [
        "!pip install pycocoevalcap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data_loader(dataset, batch_size):\n",
        "    feature_lst = []\n",
        "    index_lst = []\n",
        "    captions = []\n",
        "    for data in tqdm(dataset.batch(batch_size).take(100)):\n",
        "\n",
        "        image = data[0]\n",
        "        index = data[1].numpy()\n",
        "        feature = inceptionv3_model(image).numpy()\n",
        "\n",
        "        for i in range(feature.shape[0]):\n",
        "            feature_lst.append(feature[i].squeeze().reshape((64,2048)))\n",
        "            index_lst.append(index[i])\n",
        "            captions.append(np.array(getCapsTest(index[i])))\n",
        "\n",
        "    return feature_lst, index_lst, captions\n",
        "\n",
        "test_img_path = np.array(listdir(\"/content/content/drive/MyDrive/Dataset/test\"))"
      ],
      "metadata": {
        "id": "9yUcZDpTFh3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDataset = tf.data.Dataset.list_files(\"/content/content/drive/MyDrive/Dataset/test/*.jpg\", shuffle=True).map(lambda x: tf.py_function(load_image_inception, [x], [tf.float32, tf.int32]))\n",
        "testDataset_subset = testDataset.take(int(len(test_img_path)*0.01))"
      ],
      "metadata": {
        "id": "Z1Sib-jyFkfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_test, index_test, caption_test = test_data_loader(testDataset_subset,100)"
      ],
      "metadata": {
        "id": "GtD1NCQSFnMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1ZmpVfF03_C"
      },
      "outputs": [],
      "source": [
        "from pycocoevalcap.bleu.bleu import Bleu\n",
        "from pycocoevalcap.rouge.rouge import Rouge\n",
        "from pycocoevalcap.cider.cider import Cider \n",
        "from pycocoevalcap.meteor.meteor import Meteor\n",
        "\n",
        "def score(ground_truth, prediction):\n",
        "    \n",
        "\n",
        "    score_dict = {}\n",
        "    metrics = [(Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
        "                (Meteor(),\"METEOR\"),\n",
        "                (Rouge(), \"ROUGE_L\"),\n",
        "                (Cider(), \"CIDEr\")]\n",
        "    for scorer, method in metrics:\n",
        "\n",
        "        score, scores = scorer.compute_score(ground_truth, prediction)\n",
        "\n",
        "        if type(score) == list:\n",
        "            for m, s in zip(method, score):\n",
        "\n",
        "                score_dict[m] = s\n",
        "\n",
        "        else:  \n",
        "            score_dict[method] = score\n",
        "\n",
        "    b1,b2,b3,b4 = score_dict[\"Bleu_1\"] * 100, score_dict[\"Bleu_2\"] * 100, score_dict[\"Bleu_3\"] * 100, score_dict[\"Bleu_4\"] * 100\n",
        "    m, r, c = score_dict[\"METEOR\"] * 100, score_dict[\"ROUGE_L\"] * 100,  score_dict[\"CIDEr\"] * 100\n",
        "    blue_scores = \"BLEU-1: {} BLEU-2: {} BLEU-3: {} BLEU-4 {} \".format(b1,b2,b3,b4)\n",
        "    other_scores = \"METEOR:  {} ROGUE_L: {} CIDEr: {} \".format(m, r, c)\n",
        "    print(blue_scores)\n",
        "    print(other_scores)\n",
        "    return score_dict\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "5GG1yxzoql2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYVXxijthfu_"
      },
      "outputs": [],
      "source": [
        "start = 0\n",
        "indexes = index_test\n",
        "blue_1 = 0\n",
        "blue_2 = 0\n",
        "blue_3 = 0\n",
        "blue_4 = 0\n",
        "meteor = 0\n",
        "rouge_l = 0\n",
        "cider = 0\n",
        "counter = 0\n",
        "for i, index in enumerate(indexes):\n",
        "  predictions = {}\n",
        "  gt_caption = {}\n",
        "  captions = caption_test[i+start]\n",
        "  testim = imread('/content/content/drive/MyDrive/Dataset/test/'+str(index)+'.jpg')\n",
        " \n",
        "  for k in range(len(captions)):\n",
        "    prediction_array_of_words = evaluate_test(features_test[i+start])\n",
        "    pred_sentence = [' '.join(prediction_array_of_words[:-1])]\n",
        "    predictions['0'] = pred_sentence\n",
        "    capt_real = readCaps(getCapsTest(index))[k]\n",
        "    capt_real = capt_real[9:capt_real.find(' x_END_')]\n",
        "    gt_caption['0'] = [capt_real]\n",
        "    print(\"################SEPERATOR###########\")\n",
        "    print(gt_caption)\n",
        "    print(predictions)\n",
        "    plt.title('Real Caption:'+ capt_real + '\\n'+'Prediction Caption:' + pred_sentence[0])\n",
        "    plt.imshow(testim)\n",
        "    plt.show()  \n",
        "    #print(temp)\n",
        "    score_output = score(predictions, gt_caption)\n",
        "    blue_1 +=  score_output['Bleu_1']\n",
        "    blue_2 +=  score_output['Bleu_2']\n",
        "    blue_3 +=  score_output['Bleu_3']\n",
        "    blue_4 +=  score_output['Bleu_4']\n",
        "    meteor +=  score_output['METEOR']\n",
        "    rouge_l +=  score_output['ROUGE_L']\n",
        "    cider +=  score_output['CIDEr']\n",
        "    counter += 1\n",
        "\n",
        "    #print(gt_caption[counter] )\n",
        "blue_1 = blue_1 /  counter \n",
        "blue_2 = blue_2 /  counter \n",
        "blue_3 = blue_3 /  counter \n",
        "blue_4 = blue_4 /  counter \n",
        "meteor = meteor /  counter \n",
        "rouge_l = rouge_l / counter\n",
        "cider = cider / counter\n",
        "print(f\"Blue 1 {blue_1}, Blue 2 {blue_2} ,Blue 3 {blue_3},Blue 4 {blue_4}, Meteor {meteor}, rouge_l {rouge_l}, cider {cider}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7SoKzD-2hae"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "UPLOAD_LSTM_GROUP6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}